# Substack Scraper Configuration
# Edit these settings to customize the scraper behavior

[scraper]
# Maximum number of profiles to scrape
max_profiles = 200

# Number of times to scroll the explore page (more scrolls = more profiles loaded)
scroll_times = 5

# Maximum subscriber count to include (profiles above this will be skipped)
# Set to 0 to disable filtering
max_subscribers = 30000

# Minimum subscriber count to include
# Set to 0 to disable filtering
min_subscribers = 0

[browser]
# Run browser in headless mode (no visible window)
# Set to true for faster scraping, false for debugging
headless = false

# Page load timeout in milliseconds
timeout_ms = 60000

# Wait time after page load (milliseconds)
page_wait_ms = 3000

# Wait time after each scroll (milliseconds)
scroll_wait_ms = 2000

# Delay between each profile request (milliseconds) - prevents rate limiting
request_delay_ms = 3000

# Extra delay after errors (milliseconds)
error_delay_ms = 10000

[output]
# Output format: csv or json
format = csv

# Output filename (without extension, extension will be added based on format)
filename = substack_profiles

# Output directory (use "." for current directory)
output_dir = /Users/aadi/Documents/automated_testing

[filters]
# Comma-separated list of social platforms to extract
# Leave empty to extract all
# Options: twitter, instagram, tiktok, linkedin, facebook, youtube, github, threads, bluesky
platforms = 

# Only include profiles that have at least one social link
require_social_links = false
